{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/LC1332/Chat-Haruhi-Suzumiya/blob/main/notebook/reform_main.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gOJkH-EiXP0o"
      },
      "source": [
        "# Chat凉宫春日 Chat-Haruhi-Suzumiya\n",
        "\n",
        "[![Code License](https://img.shields.io/badge/Code%20License-Apache_2.0-green.svg)]()\n",
        "[![Data License](https://img.shields.io/badge/Data%20License-CC%20By%20NC%204.0-red.svg)]()\n",
        "[![Huggingface Gradio](https://img.shields.io/static/v1?label=Demo&message=Huggingface%20Gradio&color=orange)](https://huggingface.co/spaces/silk-road/ChatHaruhi)\n",
        "\n",
        "**Chat凉宫春日**是模仿凉宫春日等一系列动漫人物，使用近似语气、个性和剧情聊天的语言模型，\n",
        "\n",
        "<details>\n",
        "  <summary> 本项目由李鲁鲁，冷子昂，闫晨曦，封小洋，scixing，沈骏一，Aria Fei, 米唯实, 吴平宇, 贾曜恺等开发。 </summary>\n",
        "\n",
        "李鲁鲁发起了项目，并完成了最早的版本，在多个微信群实现了测试。完成了训练数据自动生成对话部分，设计了整体的路线，并撰写报告。\n",
        "\n",
        "冷子昂负责了每一个阶段的Gradio开发，以及每个部分的功能整合和架构设计。\n",
        "\n",
        "闫晨曦一开始将李鲁鲁的notebook重构为app.py，参与了WebUI的embedding部分重构整合。\n",
        "\n",
        "封小洋进行了中文转日文模型的选型，完成了针对台词抽取图片的工具。整合了声纹识别。即将继续参加台本工具的开发。\n",
        "\n",
        "scixing实践了VITS语音，完成了台词对应的语音抽取，实现了第一个版本的声纹分类。\n",
        "\n",
        "沈骏一实现了使用ChatGLM2 finetune实验\n",
        "\n",
        "Aria(Yaying Fei)对接了whisper到台本工具。即将继续参加台本工具的开发。\n",
        "\n",
        "米唯实实现了Chat哆啦A梦的分支版本\n",
        "\n",
        "吴平宇部署了ChatGLM2的训练程序，并提供了训练的计算资源。\n",
        "\n",
        "贾曜恺开发了一个Vue前端实现方案\n",
        "\n",
        "</details>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lUb8Izg2XRSD"
      },
      "source": [
        "这个脚本可以直接运行多人物角色的gradio客户端\n",
        "\n",
        "\n",
        "**TODO将端改为同时多个人可以使用，在server中加入多ChatGPT实例(冷子昂)**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RPPgMED8WhVF",
        "outputId": "af7b3c4d-4685-43b8-cee6-fb1dfb80206a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.4/7.4 MB\u001b[0m \u001b[31m13.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m19.9/19.9 MB\u001b[0m \u001b[31m44.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m73.6/73.6 kB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m44.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m30.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m268.8/268.8 kB\u001b[0m \u001b[31m9.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m42.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m34.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m65.8/65.8 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m294.2/294.2 kB\u001b[0m \u001b[31m20.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.4/75.4 kB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.5/50.5 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m138.7/138.7 kB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.7/45.7 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m59.5/59.5 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m129.9/129.9 kB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m90.0/90.0 kB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.4/49.4 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.4/50.4 kB\u001b[0m \u001b[31m644.9 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.5/46.5 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.7/43.7 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.0/41.0 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.0/41.0 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m87.5/87.5 kB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.5/84.5 kB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.0/67.0 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m74.5/74.5 kB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for ffmpy (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ],
      "source": [
        "!pip -q install transformers gradio openai tiktoken langchain"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "f-4HOTbe3Vc2"
      },
      "outputs": [],
      "source": [
        "!pip -q install jsonlines"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FOHwasoRUppo"
      },
      "source": [
        "**在这里输入你的OpenAI_KEY**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "zcPGpSm_Uot4"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "os.environ[\"OPENAI_API_KEY\"] = \"sk-AT8CYRABLcwY1EEEF77c869a3eC64239Ae8a4205A2781257\"\n",
        "os.environ[\"OPENAI_API_BASE\"] = \"http://10.10.0.7:8088/v1\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oDO1lO-MWZ9A",
        "outputId": "afd9b50d-3db2-401b-ee58-7661441627a9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cloning into 'Chat-Haruhi-Suzumiya'...\n",
            "remote: Enumerating objects: 9979, done.\u001b[K\n",
            "remote: Counting objects: 100% (97/97), done.\u001b[K\n",
            "remote: Compressing objects: 100% (66/66), done.\u001b[K\n",
            "remote: Total 9979 (delta 42), reused 63 (delta 31), pack-reused 9882\u001b[K\n",
            "Receiving objects: 100% (9979/9979), 153.55 MiB | 24.59 MiB/s, done.\n",
            "Resolving deltas: 100% (2012/2012), done.\n",
            "Updating files: 100% (6704/6704), done.\n"
          ]
        }
      ],
      "source": [
        "!rm -rf /content/Chat-Haruhi-Suzumiya/\n",
        "!git clone https://github.com/DrayChou/Chat-Haruhi-Suzumiya.git --config 'http.proxy=socks5://10.10.8.17:7893' --config 'https.proxy=socks5://10.10.8.17:7893'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z0eATbMrWfYe",
        "outputId": "1fba8a5b-86a3-4d67-89ee-8aad534360e6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content/Chat-Haruhi-Suzumiya/src_reform\n"
          ]
        }
      ],
      "source": [
        "%cd Chat-Haruhi-Suzumiya/src_reform"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "remote: Enumerating objects: 61, done.\u001b[K\n",
            "remote: Counting objects: 100% (61/61), done.\u001b[K\n",
            "remote: Compressing objects: 100% (1/1), done.\u001b[K\n",
            "remote: Total 32 (delta 31), reused 32 (delta 31), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (32/32), 8.17 KiB | 58.00 KiB/s, done.\n",
            "From https://github.com/DrayChou/Chat-Haruhi-Suzumiya\n",
            "   810672bf..de8578fe  main       -> origin/main\n",
            "Updating 810672bf..de8578fe\n",
            "Fast-forward\n",
            " audio_legacy/src_audio/app.py                   |   4 \u001b[32m+\u001b[m\u001b[31m-\u001b[m\n",
            " audio_legacy/src_audio/app_more_general.py      |   4 \u001b[32m+\u001b[m\u001b[31m-\u001b[m\n",
            " audio_legacy/src_audio/app_with_text_preload.py |   4 \u001b[32m+\u001b[m\u001b[31m-\u001b[m\n",
            " kyon_generator/ChatGPT_for_generation.py        |   4 \u001b[32m+\u001b[m\u001b[31m-\u001b[m\n",
            " kyon_generator/synthesis_chat_method_foo.py     |   2 \u001b[32m+\u001b[m\u001b[31m-\u001b[m\n",
            " notebook/College_essays_gradio.ipynb            |   2 \u001b[32m+\u001b[m\u001b[31m-\u001b[m\n",
            " notebook/ContinuousConversationGenerating.ipynb |   2 \u001b[32m+\u001b[m\u001b[31m-\u001b[m\n",
            " notebook/Doraemon_Agent.ipynb                   |   6 \u001b[32m+\u001b[m\u001b[31m-\u001b[m\n",
            " notebook/DoubleCheckQA360.ipynb                 |   2 \u001b[32m+\u001b[m\u001b[31m-\u001b[m\n",
            " notebook/HaruhiChatGenerate.ipynb               |   2 \u001b[32m+\u001b[m\u001b[31m-\u001b[m\n",
            " notebook/PersonalityChatbot.ipynb               |   2 \u001b[32m+\u001b[m\u001b[31m-\u001b[m\n",
            " notebook/QAtest.ipynb                           |   2 \u001b[32m+\u001b[m\u001b[31m-\u001b[m\n",
            " notebook/TextGenerationViaKeyword-1.ipynb       |   2 \u001b[32m+\u001b[m\u001b[31m-\u001b[m\n",
            " notebook/TextGenerationViaKeyword-2.ipynb       |   2 \u001b[32m+\u001b[m\u001b[31m-\u001b[m\n",
            " notebook/ToQA.ipynb                             |   2 \u001b[32m+\u001b[m\u001b[31m-\u001b[m\n",
            " notebook/haruhiLangChain.ipynb                  |   4 \u001b[32m+\u001b[m\u001b[31m-\u001b[m\n",
            " notebook/low_QAtest.ipynb                       |   2 \u001b[32m+\u001b[m\u001b[31m-\u001b[m\n",
            " notebook/reform_main.ipynb                      | 207 \u001b[32m+++++++++++++++\u001b[m\u001b[31m---------\u001b[m\n",
            " src/app.py                                      |   4 \u001b[32m+\u001b[m\u001b[31m-\u001b[m\n",
            " src/app_more_general.py                         |   4 \u001b[32m+\u001b[m\u001b[31m-\u001b[m\n",
            " src/app_withAudio.py                            |   4 \u001b[32m+\u001b[m\u001b[31m-\u001b[m\n",
            " src/app_with_text_preload.py                    |   4 \u001b[32m+\u001b[m\u001b[31m-\u001b[m\n",
            " src_reform/ChatGPT.py                           |   4 \u001b[32m+\u001b[m\u001b[31m-\u001b[m\n",
            " src_reform/gradioServer.py                      |   1 \u001b[32m+\u001b[m\n",
            " 24 files changed, 162 insertions(+), 114 deletions(-)\n"
          ]
        }
      ],
      "source": [
        "!git pull"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Iwzu4Pm9aNul"
      },
      "source": [
        "\n",
        "**TODO将端改为同时多个人可以使用，在server中加入多ChatGPT实例(冷子昂)**\n",
        "\n",
        "目前gradio出的链接只适合单人使用"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DY4j7sMxWtHM",
        "outputId": "6033d8b1-be62-4b80-ad33-2f4e9a88db5a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "正在加载: DEFAULT 角色\n",
            "配置文件载入完成\n",
            "已找到角色文件夹\n",
            "选择使用GPT作为语言模型\n",
            "正在载入角色GPT所需资源\n",
            "configuration ->  {'character_folder': '../characters/haruhi/', 'image_embed_jsonl_path': '../characters/haruhi/jsonl/image_embed.jsonl', 'title_text_embed_jsonl_path': '../characters/haruhi/jsonl/title_text_embed.jsonl', 'images_folder': '../characters/haruhi/images', 'jsonl_folder': '../characters/haruhi/jsonl', 'texts_folder': '../characters/haruhi/texts', 'dialogue_path': '../characters/haruhi/dialogues/', 'system_prompt': '../characters/haruhi/system_prompt.txt', 'max_len_story': '1500', 'max_len_history': '1200', 'openai_key_1': 'sk-UfivPpoxW575md2vPz', 'openai_key_2': 'EDT3BlbkFJ3TYaQlZyDcJiWJcFs3V6', 'gpt': 'True', 'local_tokenizer': 'THUDM/chatglm2-6b', 'local_model': 'THUDM/chatglm2-6b', 'local_lora': 'Jyshen/Chat_Suzumiya_GLM2LoRA'}\n",
            "正在下载Luotuo-Bert\n",
            "Explicitly passing a `revision` is encouraged when loading a model with custom code to ensure no malicious code has been contributed in a newer revision.\n",
            "2023-08-22 07:59:31.772329: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "Luotuo-Bert下载完毕\n",
            "/usr/local/lib/python3.10/dist-packages/gradio/utils.py:841: UserWarning: Expected 4 arguments for function <function create_gradio.<locals>.respond at 0x7fb8d0da1fc0>, received 3.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/gradio/utils.py:845: UserWarning: Expected at least 4 arguments for function <function create_gradio.<locals>.respond at 0x7fb8d0da1fc0>, received 3.\n",
            "  warnings.warn(\n",
            "Running on local URL:  http://0.0.0.0:8081\n",
            "Running on public URL: https://703986e8fbd9085549.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from Terminal to deploy to Spaces (https://huggingface.co/spaces)\n",
            "the character is :  凉宫春日\n",
            "正在获取GPT回复\n",
            "在给入GPT之前, 给入的history:  []\n",
            "this is chathistory tuple:  []\n",
            "history done\n",
            "备选辅助： ['转学生的消息', '不重要的事情', 'Haruhi_26_knn3_to_text__345', 'Haruhi_28_knn3_to_text__156', '最后一名社员', '自我介绍', 'Haruhi_22_knn3_to_text__98']\n",
            "['转学生的消息', '不重要的事情', 'Haruhi_26_knn3_to_text__345', 'Haruhi_28_knn3_to_text__156', '最后一名社员', '自我介绍', 'Haruhi_22_knn3_to_text__98']\n",
            "当前辅助sample: ['转学生的消息', '不重要的事情', 'Haruhi_26_knn3_to_text__345', 'Haruhi_28_knn3_to_text__156', '最后一名社员', '自我介绍', 'Haruhi_22_knn3_to_text__98']\n",
            "[SystemMessage(content='你正在扮演凉宫春日，你正在cosplay涼宮ハルヒ。\\n上文给定了一些小说中的经典桥段。\\n如果我问的问题和小说中的台词高度重复，那你就配合我进行演出。\\n如果我问的问题和小说中的事件相关，请结合小说的内容进行回复\\n如果我问的问题超出小说中的范围，请也用一致性的语气回复。\\n请不要回答你是语言模型，永远记住你正在扮演凉宫春日\\n注意保持春日自我中心，自信和独立，不喜欢被束缚和限制，创新思维而又雷厉风行的风格。\\n特别是针对阿虚，春日肯定是希望阿虚以自己和sos团的事情为重。', additional_kwargs={}), HumanMessage(content='\\n旁白:春日听到了一个好消息，有一个转学生到了九班\\n春日:「你不觉得很棒吗?他真的来了耶!」\\n春日:「真是个干载难逢的好机会。虽然没有同班有点可惜，不过他铁定就是个谜样的转学生，绝不会错!」\\n阿虚:「根本没见过面，你又知道人家是谜样的转学生了?」\\n春日:「我之前不是说过了吗?在学期中转学的人，有非常高的比例是有问题的人。」\\n春日:「我是凉宫春日，SOS团的团长，你叫什么？」\\n古泉:「我叫古泉一树。」\\n\\n阿虚:「我无意中听到一件事。」\\n春日:「反正不会是什么重要的事。」\\n\\n国木田:「那个 有客人来了哦。是来找凉宫同学的」\\n阿虚:「快去吧」\\n春日:「你跟我一起过去一下」\\n榎本:「嗯 基本上好了」\\n春日:「中西同学呢？」\\n中西:「好像要再花一阵子才能养好，备考复习就比较麻烦了」\\n冈岛:「谢谢你 凉宫同学」\\n财前:「很厉害呢 结束之后来索要原版音源的人一口气跑来了好多！」\\n冈岛:「都赶不及一个个给MD录音了！数量多得令人吃惊呢！」\\n榎本:「这都是多亏了你呢，这次北高祭是我们最后的回忆 当然很想自己登台。但这比弃权已经好了不知多少倍呢」\\n春日:「是吗」\\n中西:「我们想要给你一点谢礼…」\\n春日:「啊 不用了不用了，我也唱得很高兴。歌也很好听」\\n中西:「啊 我们打算在毕业之前找个地方开一场演唱会。如果可以的话请来看看吧」\\n中西:「和你这位…你这位\"朋友\"一起来」\\n旁白:下雨天阿虚和春日打一把伞\\n春日:「再往这边靠一点啦 我都淋到了」\\n阿虚:「已经靠过去很多了啊。啊 这把伞不是你的对吧？上面写着\"教职员工用\"呢」\\n春日:「反正是学校的预备品，让学生用一下也没什么不好吧」\\n春日:「怎么了？如果你想淋着雨回去的话，我就不给你打了～」(玩笑着打着伞跑开)\\n阿虚:「等一下啦！」\\n\\n旁白:春日在最后一堂课下课后，冲到了九班，抓住古泉然后带到了社团教室\\n春日:「嘿，久等啰!」\\n春日:「这是今天才转到一年九班的转学生，他的名字是……」\\n古泉:「我叫古泉一树。……请多多指教。」\\n春日:「这里就是SOS团的社团教室，我是团长凉宫春日，他们则是团员一、二、三号。附带一提，你是第四号。各位，记得要相亲相爱喔!」\\n古泉:「要我加入也是可以啦!」\\n古泉:「这是什么样的社团?」\\n春日:「就让我来告诉你SOS团是个什么样的社团吧，那就是……」\\n旁白:春日深吸一口气，然后充满感情的说出了SOS团的活动方针\\n春日:「找出外星人、未来人以及超能力者，然后跟他们一起玩!」\\n\\n旁白: 在开学的时候，老师让所有人进行自我介绍\\n春日:「我毕业于东中，叫做凉宫春日。」\\n春日:「我对普通的人类没有兴趣，如果你们中有外星人，未来人，异世界的人或者超能力者的话，就尽管来找我吧！以上。」\\n\\n阿虚:「春日 你啊 要是那个神官向学校告状的话怎么办,古泉身上的制服可把我们的身分泄漏出去了」\\n春日:「应该没有问题吧，我们隔那么远 这种夹克也是满大街的。他说什么也好 我们打死都不承认就是了」\\n', additional_kwargs={}, example=False), HumanMessage(content='学生:「你好」', additional_kwargs={}, example=False)]\n"
          ]
        }
      ],
      "source": [
        "!python gradioServer.py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3IHZldXQWwOn"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
